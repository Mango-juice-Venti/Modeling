{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0dd9207-cbe8-46dd-b814-eef79256e42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[34]\tvalid_0's rmse: 12.9234\n",
      "[BLEND] best_alpha=0.900 | Weighted SMAPE=373.0926\n",
      "[✅] 저장 완료: C:\\Users\\LG\\Downloads\\submission_blended_final.csv | 매칭행=70/70 | 누락컬럼=0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "리조트 식음업장 — LightGBM 듀얼 회귀 앙상블 (Tweedie + log1p)\n",
    "+ 기존 성능 기반 파라미터 사용\n",
    "+ 시간누수 방지 타깃인코딩\n",
    "+ 업장가중 SMAPE (미라시아·달하 우선순위)\n",
    "+ 블렌딩 최적화 + 7일 재귀예측 + 퍼지매칭 제출\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, re, unicodedata, difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "# ====================== Config ======================\n",
    "BASE_DIR = Path(\"C:/Users/LG/Downloads\")\n",
    "TRAIN_FILE = BASE_DIR / \"re_train.csv\"\n",
    "TEST_GLOB = str(BASE_DIR / \"TEST_*processed.csv\")\n",
    "SAMPLE_SUB = BASE_DIR / \"곤지암submission.csv\"\n",
    "OUT_FILE = BASE_DIR / \"submission_blended_final.csv\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "VALID_LAST_DAYS = 28\n",
    "POS_SAMPLE_BOOST = 4.0\n",
    "CAT_COLS = [\"메뉴명\", \"요일\", \"menu_category\", \"quarter\"]\n",
    "\n",
    "# ====================== 평가 함수 ======================\n",
    "def smape_ignore_zero(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    m = y_true != 0\n",
    "    if m.sum() == 0:\n",
    "        return 0.0\n",
    "    yt, yp = y_true[m], y_pred[m]\n",
    "    return 100.0 * np.mean(2.0 * np.abs(yp - yt) / (np.abs(yt) + np.abs(yp) + eps))\n",
    "\n",
    "def weighted_smape(df):\n",
    "    weights = {\"미라시아\": 2.0, \"달하\": 2.0}\n",
    "    score = 0.0\n",
    "    for s, group in df.groupby(\"영업장명\"):\n",
    "        w = weights.get(s, 1.0)\n",
    "        smapes = [smape_ignore_zero(sub[\"y_true\"], sub[\"y_pred\"]) for _, sub in group.groupby(\"영업장명_메뉴명\") if (sub[\"y_true\"] != 0).any()]\n",
    "        if smapes:\n",
    "            score += w * np.mean(smapes)\n",
    "    return score\n",
    "\n",
    "# ====================== 학습 함수 ======================\n",
    "def train_models_and_blend(train_df):\n",
    "    df = train_df.copy()\n",
    "    df[\"영업일자\"] = pd.to_datetime(df[\"영업일자\"])\n",
    "    df = df[df[\"매출수량\"] >= 0]\n",
    "    df = df.sort_values([\"영업장명_메뉴명\", \"영업일자\"])\n",
    "\n",
    "    for col in CAT_COLS:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "\n",
    "    feats = [c for c in df.columns if c not in [\"매출수량\", \"영업일자\", \"영업장명_메뉴명\", \"영업장명\"]]\n",
    "    y = df[\"매출수량\"].values\n",
    "\n",
    "    max_date = df[\"영업일자\"].max()\n",
    "    valid_start = max_date - pd.Timedelta(days=VALID_LAST_DAYS - 1)\n",
    "    train_idx = df[\"영업일자\"] < valid_start\n",
    "    valid_idx = df[\"영업일자\"] >= valid_start\n",
    "\n",
    "    X_tr, X_val = df.loc[train_idx, feats], df.loc[valid_idx, feats]\n",
    "    y_tr, y_val = y[train_idx], y[valid_idx]\n",
    "    w_tr = np.where(y_tr > 0, POS_SAMPLE_BOOST, 1.0)\n",
    "    w_val = np.where(y_val > 0, POS_SAMPLE_BOOST, 1.0)\n",
    "\n",
    "    best_params = {\n",
    "        \"objective\": \"tweedie\",\n",
    "        \"tweedie_variance_power\": 1.11,\n",
    "        \"learning_rate\": 0.06,\n",
    "        \"max_depth\": 9,\n",
    "        \"subsample\": 0.60,\n",
    "        \"colsample_bytree\": 0.71,\n",
    "        \"min_child_weight\": 2.9,\n",
    "        \"lambda_l2\": 2.83,\n",
    "        \"metric\": \"rmse\",\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    dtrainA = lgb.Dataset(X_tr, label=y_tr, weight=w_tr, categorical_feature=CAT_COLS)\n",
    "    dvalA = lgb.Dataset(X_val, label=y_val, weight=w_val, categorical_feature=CAT_COLS)\n",
    "\n",
    "    modelA = lgb.train(best_params, dtrainA, valid_sets=[dvalA], callbacks=[lgb.early_stopping(100)])\n",
    "    predA = np.clip(modelA.predict(X_val), 0, None)\n",
    "\n",
    "    log_y_tr = np.log1p(y_tr[y_tr > 0])\n",
    "    X_tr_pos = X_tr[y_tr > 0]\n",
    "    w_tr_pos = w_tr[y_tr > 0]\n",
    "    dtrainB = lgb.Dataset(X_tr_pos, label=log_y_tr, weight=w_tr_pos, categorical_feature=CAT_COLS)\n",
    "    modelB = lgb.train({**best_params, \"objective\": \"regression\"}, dtrainB, num_boost_round=2000)\n",
    "    predB = np.expm1(np.clip(modelB.predict(X_val), 0, None))\n",
    "\n",
    "    best_score, best_alpha = float(\"inf\"), 0.5\n",
    "    for alpha in np.linspace(0.1, 0.9, 17):\n",
    "        blended = (1 - alpha) * predA + alpha * predB\n",
    "        score = weighted_smape(pd.DataFrame({\n",
    "            \"영업장명\": df.loc[valid_idx, \"영업장명\"].values,\n",
    "            \"영업장명_메뉴명\": df.loc[valid_idx, \"영업장명_메뉴명\"].values,\n",
    "            \"y_true\": y_val,\n",
    "            \"y_pred\": blended\n",
    "        }))\n",
    "        if score < best_score:\n",
    "            best_score, best_alpha = score, alpha\n",
    "\n",
    "    print(f\"[BLEND] best_alpha={best_alpha:.3f} | Weighted SMAPE={best_score:.4f}\")\n",
    "    return (modelA, modelB, best_alpha), feats\n",
    "\n",
    "# ====================== 퍼지 제출 저장 ======================\n",
    "def parse_tag_day(label: str):\n",
    "    if not isinstance(label, str): label = str(label)\n",
    "    m_tag = re.search(r\"(TEST_\\d{2})\", label, flags=re.IGNORECASE)\n",
    "    m_day = re.findall(r\"(\\d+)\", label)\n",
    "    tag = m_tag.group(1).upper() if m_tag else None\n",
    "    k   = int(m_day[-1]) if m_day else None\n",
    "    return tag, k\n",
    "\n",
    "def norm_name(s: str):\n",
    "    if not isinstance(s, str): s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s).strip().lower()\n",
    "    repl = {\"·\":\" \",\"•\":\" \",\"ㆍ\":\" \",\"‧\":\" \",\"–\":\"-\",\"—\":\"-\",\"’\":\"'\", \"“\":\"\\\"\", \"”\":\"\\\"\",\n",
    "            \"（\":\"(\",\"）\":\")\",\"【\":\"[\",\"】\":\"]\"}\n",
    "    for k,v in repl.items(): s = s.replace(k, v)\n",
    "    s = re.sub(r\"[()\\[\\]{}]\", \" \", s)\n",
    "    s = re.sub(r\"[\\/\\-_]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def build_row_index_map(pred_full):\n",
    "    pred_index_map = {}\n",
    "    for ridx, row in pred_full.iterrows():\n",
    "        t, k = parse_tag_day(ridx)\n",
    "        if (t is not None) and (k is not None):\n",
    "            pred_index_map[(t, k)] = row\n",
    "    return pred_index_map\n",
    "\n",
    "def build_column_mapping(sample_cols, pred_cols, cutoff=0.90):\n",
    "    pred_norm2orig = {norm_name(c): c for c in pred_cols}\n",
    "    mapping, exact, fuzzy, unmatched = {}, 0, 0, []\n",
    "    pred_norm_keys = list(pred_norm2orig.keys())\n",
    "    for sc in sample_cols:\n",
    "        ns = norm_name(sc)\n",
    "        if ns in pred_norm2orig:\n",
    "            mapping[sc] = pred_norm2orig[ns]; exact += 1\n",
    "        else:\n",
    "            cand = difflib.get_close_matches(ns, pred_norm_keys, n=1, cutoff=cutoff)\n",
    "            if cand: mapping[sc] = pred_norm2orig[cand[0]]; fuzzy += 1\n",
    "            else: mapping[sc] = None; unmatched.append(sc)\n",
    "    return mapping, exact, fuzzy, unmatched\n",
    "\n",
    "def save_submission(sample, pred_full, out_path):\n",
    "    pred_index_map = build_row_index_map(pred_full)\n",
    "    submission = sample.copy()\n",
    "    idx_labels = submission[\"영업일자\"].tolist()\n",
    "    item_cols  = submission.columns.tolist()[1:]\n",
    "    pred_cols = [] if pred_full is None or pred_full.empty else pred_full.columns.tolist()\n",
    "    col_map, exact, fuzzy, unmatch = build_column_mapping(item_cols, pred_cols)\n",
    "\n",
    "    out_vals, matched_rows = [], 0\n",
    "    for lbl in idx_labels:\n",
    "        t, k = parse_tag_day(lbl)\n",
    "        if (t, k) in pred_index_map:\n",
    "            sr = pred_index_map[(t, k)]\n",
    "            row_vals = [float(max(0.0, sr.get(col_map.get(sc), 0.0))) for sc in item_cols]\n",
    "            matched_rows += 1\n",
    "        else:\n",
    "            row_vals = [0.0] * len(item_cols)\n",
    "        out_vals.append(row_vals)\n",
    "\n",
    "    final_df = pd.DataFrame(out_vals, columns=item_cols)\n",
    "    final_df.insert(0, \"영업일자\", idx_labels)\n",
    "    final_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[✅] 저장 완료: {out_path} | 매칭행={matched_rows}/{len(idx_labels)} | 누락컬럼={len(unmatch)}\")\n",
    "\n",
    "# ====================== main ======================\n",
    "def main():\n",
    "    train = pd.read_csv(TRAIN_FILE,encoding='cp949')\n",
    "    sample = pd.read_csv(SAMPLE_SUB)\n",
    "\n",
    "    category_map = {}\n",
    "    for col in CAT_COLS:\n",
    "        train[col] = train[col].astype(\"category\")\n",
    "        category_map[col] = train[col].cat.categories\n",
    "\n",
    "    models, feats = train_models_and_blend(train)\n",
    "\n",
    "    test_files = sorted(glob.glob(TEST_GLOB))\n",
    "    all_preds = []\n",
    "\n",
    "    for tf in test_files:\n",
    "        test_df = pd.read_csv(tf)\n",
    "        test_df[\"영업일자\"] = pd.to_datetime(test_df[\"영업일자\"])\n",
    "        test_df = test_df.sort_values([\"영업장명_메뉴명\", \"영업일자\"])\n",
    "\n",
    "        for col in CAT_COLS:\n",
    "            test_df[col] = test_df[col].astype(str)\n",
    "            test_df[col] = test_df[col].apply(lambda x: x if x in category_map[col] else \"기타\")\n",
    "            cats = list(category_map[col]) + ([\"기타\"] if \"기타\" not in category_map[col] else [])\n",
    "            test_df[col] = pd.Categorical(test_df[col], categories=cats)\n",
    "\n",
    "        last_date = test_df[\"영업일자\"].max()\n",
    "        modelA, modelB, alpha = models\n",
    "        preds = []\n",
    "\n",
    "        for k in range(1, 8):\n",
    "            pred_date = last_date + timedelta(days=k)\n",
    "            test_df_day = test_df.copy()\n",
    "            test_df_day[\"영업일자\"] = pred_date\n",
    "            X = test_df_day[feats].copy()\n",
    "\n",
    "            num_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "            X[num_cols] = X[num_cols].fillna(0.0)\n",
    "\n",
    "            yhatA = np.clip(modelA.predict(X), 0, None)\n",
    "            yhatB = np.expm1(np.clip(modelB.predict(X), 0, None))\n",
    "            yhat = np.maximum((1 - alpha) * yhatA + alpha * yhatB, 1.0)\n",
    "\n",
    "            row = {\"영업일자\": f\"{Path(tf).stem}+{k}일\"}\n",
    "            row.update(dict(zip(test_df_day[\"영업장명_메뉴명\"], yhat)))\n",
    "            preds.append(row)\n",
    "\n",
    "        preds_df = pd.DataFrame(preds).set_index(\"영업일자\")\n",
    "        all_preds.append(preds_df)\n",
    "\n",
    "    if all_preds:\n",
    "        pred_full = pd.concat(all_preds)\n",
    "        save_submission(sample, pred_full, OUT_FILE)\n",
    "    else:\n",
    "        print(\"⚠️ 예측 실패 또는 테스트 파일 누락\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
